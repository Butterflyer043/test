{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "source code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh7vDqFiMnS1"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Mar  1 10:23:07 2021\n",
        "\n",
        "@author: Jinqi Zhang\n",
        "\"\"\"\n",
        "\n",
        "#* source_code.py\n",
        "#*\n",
        "#* ANLY 555 Spring 2021\n",
        "#* Project 2\n",
        "#*\n",
        "#* Due on: 3/8/2021\n",
        "#* Authors: Jinqi Zhang, Jingyi Wang, Jinglin Liang, Xueyan Liu\n",
        "#*\n",
        "#*\n",
        "#* In accordance with the class policies and Georgetown's\n",
        "#* Honor Code, I certify that, with the exception of the\n",
        "#* class resources and those items noted below, I have neither\n",
        "#* given nor received any assistance on this project other than\n",
        "#* the TAs, professor, textbook and teammates.\n",
        "#*\n",
        "#* References not otherwise commented within the program source code.\n",
        "#* Note that you should not mention any help from the TAs, the professor,\n",
        "#* or any code taken from the class textbooks.\n",
        "#*\n",
        "\n",
        "#=====================================================================\n",
        "# Superclass: DataSet\n",
        "#\n",
        "# Subclass: \n",
        "# TimeSeriesDataSet\n",
        "# TextDataSet\n",
        "# QuantDataSet\n",
        "# QualDataSet\n",
        "#=====================================================================\n",
        "\n",
        "\n",
        "import nltk\n",
        "import regex\n",
        "import string\n",
        "import unicodedata\n",
        "nltk.download('stopwords')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms_nlbzhe0H0"
      },
      "source": [
        "# Super Class: **DataSet**\n",
        "Public Member Functions\n",
        "```\n",
        "def \t__init__ (self, filename)  \n",
        "def \tclean (self)  \n",
        "def \texplore (self, plot_type, column1, column2=None)  \n",
        "def \tmean (self, column_name)  \n",
        "def \tmedian (self, column_name_median)  \n",
        "def \tmode (self, column_name_mode)\n",
        "def \torder (self, column_name_order, decreasing)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qifd9oaevK4"
      },
      "source": [
        "class DataSet:\n",
        "    \n",
        "    def __init__(self, filename):\n",
        "        \"\"\"Constructor for super class Dataset\"\"\"\n",
        "        self._filename = filename\n",
        "    \n",
        "    def _readFromCSV(self):\n",
        "        \"\"\"The function could read csv file\"\"\"\n",
        "        self.df = pd.read_csv(self._filename)\n",
        "\n",
        "    def _load(self):\n",
        "        \"\"\"The function could ask the user for the type of file\"\"\"\n",
        "        self._type = input(\"\"\"input your dataset type and get instruction of each type\n",
        "                           \\ntype of data set (quantitative/qualitative/timeseries/textdata):\"\"\")\n",
        "       \n",
        "        if self._type == \"qualitative\":\n",
        "            print(\"\"\"Call QualDataSet() for qualitative data.\n",
        "                  \\nIncluding\n",
        "                  \\nclean() -- fill in missing values with the mode\n",
        "                  \\nexplore() -- create hist or pie plots \\nDefault: explore(plot_type_qual, column_qual)\n",
        "                  \\ntable() -- show the frequency of each category of a certain column \\nDefault: table(column_table) \\n\n",
        "                  \"\"\")\n",
        "        elif self._type == \"quantitative\":\n",
        "            print(\"\"\"Call QuantDataSet() for quantitative data.\n",
        "                  \\nIncluding\n",
        "                  \\nclean() -- fill in missing values with the mean\n",
        "                  \\nexplore() -- create hist or scatter plots \\nDefault: explore(plot_type, column1, column2=None)\n",
        "                  \\nmean() -- get the mean of certain quantitative column \\nDefault: mean(column_name)\n",
        "                  \\nmedian() -- get the median of certain quantitative column \\nDefault: median(column_name_median)\n",
        "                  \\nmode() -- get the mode of certain quantitative column \\nDefault: mode(column_name_mode)\n",
        "                  \\norder() -- present certain quantitative column by specific order \\nDefault: order(column_name_order) \\n\n",
        "                  \"\"\")\n",
        "        elif self._type == \"timeseries\":\n",
        "            print(\"\"\"Call TimeSeriesDataSet() for timeseries data.\n",
        "                  \\nIncluding\n",
        "                  \\nclean() -- run a median filter with optional parameters which determine the filter size and return the dataframe with new column of clean data \\nDefault: clean(tsColnameList, filter_size=7)\n",
        "                  \\nexplore() -- create timeseries or lag value relationship plots \\nDefault: explore(tsColnameList, date_colname=None, lag=1, vis_type=\"all\")\n",
        "                  \\nget_dataframe() -- get a dataframe with certain columns \\nDefault: get_dataframe(tsColnameList=None)\n",
        "                  \\nget_colname() -- get the column names\n",
        "                  \\ntransformation(), differencing(), movingaverage() -- methods to remove trend and seasonality \\nDefault: transformation(tsColnameList, method=\"log\", power=0.5) \\ndifferencing(tsColnameList, differences=1) \\nmovingaverage(tsColnameList, window=3) \\n\n",
        "                  \"\"\")\n",
        "        elif self._type == \"textdata\":\n",
        "            print(\"\"\"Call TextDataSet() for text data.\n",
        "                  \\nIncluding\n",
        "                  \\nclean() -- choose whether or not to remove stopwords, remove punctuations, remove diacritics, lowercase, stem and lemmatize and return a token list \\nDefault: clean(colname, lower=True, remove_diacritics=True, remove_punct=True, remove_stop=True, stem_tokens=False, lemmatize_tokens=False)\n",
        "                  \\nexplore() -- create worldcloud or dispersion plots \\nDefault: explore(token_list, worldcloud=True, dispersion=True)\n",
        "                  \\ntoken_list() -- change the nested list to a flat list \\nDefault: token_list(nested_list)\n",
        "                  \\nwordfrequency() -- get the number of times each word appears \\nDefault: wordfrequency(token_list, n, ascending=True) \\n\n",
        "                  \"\"\")\n",
        "        else:\n",
        "            raise ValueError(\"Unavailable type.\")\n",
        "        \n",
        "    def clean(self):\n",
        "        \"\"\"The function could get instruction of cleaning the dataset for each type\"\"\"\n",
        "        if self._type == \"qualitative\":\n",
        "            print(\"please call: QualDataSet(filename).clean() \\n\")\n",
        "        elif self._type == \"quantitative\":\n",
        "            print(\"please call: QuantDataSet(filename).clean() \\n\")\n",
        "        elif self._type == \"timeseries\":\n",
        "            print(\"\"\"please call: TimeSeriesDataSet(filename).clean() \\nDefault: clean(tsColnameList=None, filter_size=7) \\n\"\"\")\n",
        "        elif self._type == \"textdata\":\n",
        "            print(\"\"\"please call: TextDataSet(filename).clean() \\nDefault: clean(lower=True, remove_diacritics=True, remove_punct=True, remove_stop=True, stem_tokens=False, lemmatize_tokens=False) \\n\"\"\")\n",
        "        else:\n",
        "            raise ValueError(\"Unavailable type.\")\n",
        "    \n",
        "    def explore(self):\n",
        "        \"\"\"The function could get instruction of creating visualizations of data for each type\"\"\"\n",
        "        if self._type == \"qualitative\":\n",
        "            print(\"\"\"please call: QualDataSet(filename).explore() \\nDefault: explore(plot_type_qual, column_qual) \\n\"\"\")\n",
        "        elif self._type == \"quantitative\":\n",
        "            print(\"\"\"please call: QuantDataSet(filename).explore() \\nDefault: explore(plot_type, column1, column2=None) \\n\"\"\")\n",
        "        elif self._type == \"timeseries\":\n",
        "            print(\"\"\"please call: TimeSeriesDataSet(filename).explore() \\nDefault: explore(tsColnameList, date_colname=None, lag=1, vis_type=\"all\") \\n\"\"\")\n",
        "        elif self._type == \"textdata\":\n",
        "            print(\"\"\"please call: TextDataSet(filename).explore() \\nDefault: explore(token_list, worldcloud=True, dispersion=True) \\n\"\"\")\n",
        "        else:\n",
        "            raise ValueError(\"Unavailable type.\")\n",
        "        \n",
        "    def head(self):\n",
        "        \"\"\"The function could get the head of the dataset\"\"\"\n",
        "        print(self.df.head())\n",
        "        \n",
        "    def colname(self):\n",
        "        \"\"\"The function could get the column names\"\"\"\n",
        "        print(list(self.df))\n",
        "        \n",
        "    def colnum(self):\n",
        "        \"\"\"The function could get the number of columns\"\"\"\n",
        "        print(self.df.shape[1])\n",
        "        \n",
        "    def rownum(self):\n",
        "        \"\"\"The function could get the number of rows\"\"\"\n",
        "        print(self.df.shape[0])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Return specific coordinate of dataframe.\"\"\"\n",
        "        print(self.df.loc[index[0]][index[1]])\n",
        "    \n",
        "    def getcol(self, col):\n",
        "        \"\"\"Return specific column of dataframe.\"\"\"\n",
        "        print(self.df[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJiYlv6TdSMO"
      },
      "source": [
        "# Subclass: **TimeSeriesDataSet**\n",
        "\n",
        "Public Member Functions\n",
        "```\n",
        "def \t__init__ (self, filename)\n",
        "def \tget_dataframe (self, tsColnameList=None)\n",
        "def \tget_colname (self)\n",
        "def \tclean (self, tsColnameList, filter_size=7)\n",
        "def \texplore (self, tsColnameList, date_colname=None, lag=1, vis_type=\"all\")\n",
        "def \ttransformation (self, tsColnameList, method=\"log\", power=0.5)\n",
        "def \tdifferencing (self, tsColnameList, differences=1)\n",
        "def \tmovingaverage (self, tsColnameList, window=3)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy0AwZHIdSly"
      },
      "source": [
        "# Subclass: TimeSeriesDataSet\n",
        "class TimeSeriesDataSet(DataSet):\n",
        "    \"\"\" \n",
        "    This is a subclass for DataSet for handling time series data. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        \"\"\" \n",
        "        The constructor for TimeSeriesDataSet subclass. \n",
        "  \n",
        "        Parameters: \n",
        "           filename (str): The name of test file\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(filename) \n",
        "        # inherit self.df\n",
        "        DataSet._readFromCSV(self)  \n",
        "        \n",
        "    def get_dataframe(self,tsColnameList = None):\n",
        "        \"\"\" \n",
        "        get_dataframe Method:\n",
        "        Get dataframe with selected columns names or full columns\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "      \n",
        "        Returns: \n",
        "        dataframe: The dataframe with selected columns names\n",
        "        \"\"\"\n",
        "        if tsColnameList!= None:\n",
        "            # check arguments type and check if inputed colnames are correct.\n",
        "            if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())):\n",
        "                return (self.df[tsColnameList])\n",
        "            # or raise error\n",
        "            else:\n",
        "                raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample: df.get_dataframe([\"var1\",\"var2\"])\"\"\".format(tsColnameList))\n",
        "\n",
        "        else:\n",
        "            return (self.df)\n",
        "        \n",
        "    def get_colname(self):\n",
        "        \"\"\" \n",
        "        get_colname Method:\n",
        "        Get columns names of dataframe\n",
        "  \n",
        "        Returns: \n",
        "        list: The a list of column names\n",
        "        \"\"\"\n",
        "        return list(self.df.columns.tolist())\n",
        "    \n",
        "    def clean(self,tsColnameList,filter_size=7):\n",
        "        \"\"\" \n",
        "        clean Method:\n",
        "        Clean the selected timeseries data by median filter algorithm with inputed filter size \n",
        "        Add cleaned data as new columns to orginal dataframe.\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "        filter_size (int) : filter size of median filter (default = 7)\n",
        "      \n",
        "        Returns: \n",
        "        dataframe: The dataframe with cleaned value columns \n",
        "        \"\"\"\n",
        "        # check tsColnameList type and check if inputed colnames are correct.\n",
        "        if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())) :\n",
        "            # check filter_size type\n",
        "            if isinstance(filter_size, int):\n",
        "                new_column_list = []\n",
        "                for i in tsColnameList:\n",
        "                  # setup new cols name\n",
        "                  new_column = str(\"cleaned_\"+i)\n",
        "                  self.df[new_column] = self.df[i]\n",
        "                  # create list for storing new cols\n",
        "                  new_column_list.append(new_column)\n",
        "        \n",
        "                  # get data of that col \n",
        "                  col_temp = self.df[i]\n",
        "        \n",
        "                  # update dats by median\n",
        "                  for j in range(0, len(col_temp)-filter_size):\n",
        "                    window_list = col_temp[j:j+filter_size]\n",
        "                    self.df[new_column][j] = np.median(window_list)\n",
        "                  # update edge data \n",
        "                  for k in range (len(col_temp)-filter_size+1,len(col_temp)):\n",
        "                    window_list = col_temp[k:len(col_temp)]\n",
        "                    self.df[new_column][k] = np.median(window_list)\n",
        "\n",
        "                return (self.df[new_column_list])\n",
        "            else:\n",
        "                raise TypeError(\"\"\"filter_size = {0} is invalid. The argument: filter_size only accepts positive integer. \n",
        "                                 \\nExample: df.clean([\"var1\"],filter_size = 7)\"\"\".format(filter_size))\n",
        "        \n",
        "        else:\n",
        "            raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample: df.clean([\"var1\"],filter_size = 7)\"\"\".format(tsColnameList))\n",
        "\n",
        "\n",
        "\n",
        "    def explore(self,tsColnameList,date_colname=None,lag=1, vis_type = \"all\"):\n",
        "        \"\"\"\n",
        "        explore Method: \n",
        "        Create 2 type visulizations (timesseries plot and lag plot) for time series data.\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "        date_colname (str) : The name of date columns \n",
        "        lag (int) : The lag for lag plots, (default = 1)\n",
        "        vis_type (str) : The type of visulization:  \"all\" for output both times series plots and lag plots;\"ts\" for only output timesseries plots;\"lag\" for only output lag plots.  (default = \"all\")\n",
        "      \n",
        "        \"\"\"\n",
        "        def ts_plot(): \n",
        "        # ts_plot function: create timesseries plot.\n",
        "            plt.figure(figsize=(10,5))#figsize=(20,10)\n",
        "            plot_list = []\n",
        "            plt.grid()\n",
        "            # add ts lines to one plot\n",
        "            for i in tsColnameList:\n",
        "              plot, = plt.plot(pd.to_datetime(self.df[date_colname]), self.df[i], marker='', linestyle='-')\n",
        "              plot_list.append(plot)\n",
        "            # setup labels \n",
        "            ylab = tsColnameList[0]\n",
        "            plt.ylabel(ylab)\n",
        "            plt.title(\"Time Series Plot of \"+ylab)\n",
        "            plt.xlabel(date_colname)\n",
        "            #ylab = ' '.join('{},'.format(k) for k in tsColnameList)\n",
        "            ylab = tsColnameList[0]\n",
        "            plt.ylabel(ylab)\n",
        "            plt.legend(plot_list,tsColnameList)\n",
        "            plt.show()\n",
        "\n",
        "        def lag_plot():\n",
        "        # lag_plot function: create lag plot.\n",
        "            \n",
        "          # create a plot for each column\n",
        "          for i in tsColnameList:\n",
        "              colname = i\n",
        "              value =  self.df[colname] #self.df[colname]\n",
        "              length = len(value)\n",
        "              plt.figure(figsize=(10,5))#figsize=(20,10)\n",
        "              plt.grid()\n",
        "              plt.plot(value[0:length-lag],value[lag:length] ,linestyle='', marker='o', markersize=0.9, color=\"purple\")\n",
        "              # set uo labels\n",
        "              plt.title(\"Lag Plot of \"+str(colname)+\" ( lag = \"+str(lag)+\")\")\n",
        "              plt.xlabel(colname+r\"$_{(t)}$\")\n",
        "              footnote = \"(t+\" +str(lag)+  \")\"\n",
        "              y_lab = colname+ r\"$_{{{}}}$\".format(footnote)\n",
        "              plt.ylabel(y_lab)\n",
        "              plt.show()\n",
        "        \n",
        "        # check vis_type inputed value\n",
        "        if vis_type == \"all\":\n",
        "          tsplot = True\n",
        "          lagplot = True\n",
        "        elif vis_type == \"ts\":\n",
        "          tsplot = True\n",
        "          lagplot = False\n",
        "        elif vis_type  == \"lag\":\n",
        "          tsplot = False\n",
        "          lagplot = True \n",
        "        else:\n",
        "          # if wrong raise errror\n",
        "          raise ValueError(\"\"\"vis_type = {0} is invalid. The available vis_type contains: \n",
        "                           \\n   * \"all\" for output both times series plots and lag plots,\n",
        "                           \\n   * \"ts\" for only output timesseries plots.\n",
        "                           \\n   * \"lag\" for only output lag plots.\n",
        "                             \\nExample: df.explore([\"var1],date_colname=\"Date\",lag=2, vis_type = \"ts\")\"\"\".format(vis_type))\n",
        "        \n",
        "        # check tsColnameList type and check if inputed colnames are correct.                           \n",
        "        if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())):\n",
        "          if tsplot == True:\n",
        "             # check if date_colname correct\n",
        "            if isinstance(date_colname, str) and (date_colname in self.df.columns.to_list()):\n",
        "              ts_plot()\n",
        "            else:\n",
        "              raise TypeError(\"\"\"date_colname = {0} is invalid. The argument: lagdate_colname only accepts a column name string that stores the date infomation. \n",
        "                                 \\nExample: df.explore([\"var1],date_colname=\"Date\",lag=2, vis_type = \"ts\")\"\"\".format(date_colname))\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "          if lagplot == True:\n",
        "             # check if inputed lag vaule correct\n",
        "            if isinstance(lag, int):\n",
        "             lag_plot()\n",
        "            else:\n",
        "              raise TypeError(\"\"\"lag = {0} is invalid. The argument: lag only accepts positive integer. \n",
        "                                 \\nExample: df.explore([\"var1],date_colname=\"Date\",lag=2, vis_type = \"ts\")\"\"\".format(lag))\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "        else:\n",
        "            raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample:  df.explore([\"var1],date_colname=\"Date\",lag=2, vis_type = \"ts\")\"\"\".format(tsColnameList))\n",
        "    \n",
        "        \n",
        "    def transformation(self,tsColnameList,method=\"log\",power=0.5):\n",
        "        \"\"\" \n",
        "        transformation Method:\n",
        "        Transform the selected timeseries data by log or power algorithm \n",
        "        Add transformed data as new columns to orginal dataframe.\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "        method (str) : The method type: \"log\" or power\n",
        "        power (int or float) : power for power algorithm  (default = 0.5)\n",
        "      \n",
        "        Returns: \n",
        "        dataframe: The dataframe of transformed value columns \n",
        "        \"\"\"\n",
        "        # check tsColnameList type and check if inputed colnames are correct.                           \n",
        "        if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())) :\n",
        "            if  method == \"log\":\n",
        "              new_column_list = []\n",
        "              for i in tsColnameList:\n",
        "                # setup new cols name\n",
        "                new_column = str(\"logged_\"+i)\n",
        "                self.df[new_column] = np.log(self.df[i])\n",
        "                # create list for storing new cols\n",
        "                new_column_list.append(new_column)              \n",
        "              return (self.df[new_column_list])\n",
        "\n",
        "\n",
        "            elif method == \"power\":\n",
        "              if isinstance(power, (float, int)):\n",
        "                new_column_list = []\n",
        "                for i in tsColnameList:\n",
        "                  # setup new cols name\n",
        "                  new_column = str(\"powered_\"+i)\n",
        "                  self.df[new_column] = (self.df[i])**power\n",
        "                  # create list for storing new cols\n",
        "                  new_column_list.append(new_column)              \n",
        "                return (self.df[new_column_list])\n",
        "              else:\n",
        "              # raise error  for wrong power value\n",
        "                raise TypeError(\"\"\"power = {0} is invalid. The argument: lag only accepts integer or float. \n",
        "                                 \\nExample: df.transformation([\"var1],method = \"power\",power=0.8)\"\"\".format(power))\n",
        "\n",
        "            else:\n",
        "              # raise error  for wrong method type\n",
        "              raise ValueError(\"\"\"method = {0} is invalid. The available method contains: \n",
        "                               \\n   * \"log\" for applying log transformation,\n",
        "                               \\n   * \"power\" for applying power transformation.\n",
        "                               \\nExample:  df.transformation([\"var1],method = \"power\",power=0.8)\"\"\".format(method))\n",
        "        else:\n",
        "        # raise error  for wrong tsColnameList\n",
        "          raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample:  df.transformation([\"var1],method = \"power\",power=0.8)\"\"\".format(tsColnameList))\n",
        "\n",
        "\n",
        "    def differencing(self,tsColnameList,differences = 1):\n",
        "        \"\"\" \n",
        "        differencing Method:\n",
        "        Updating the selected timeseries data by differencing algorithm \n",
        "        Add differenced data as new columns to orginal dataframe.\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "        differences (int) : differencing lag value  (default = 1)\n",
        "      \n",
        "        Returns: \n",
        "        dataframe: The dataframe of differenced value columns \n",
        "        \"\"\"\n",
        "        if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())) :\n",
        "            if isinstance(differences, (int)):\n",
        "              new_column_list = []\n",
        "              for i in tsColnameList:\n",
        "                # setup new cols name\n",
        "                new_column = str(\"diffed_\"+i)\n",
        "                new_column_list.append(new_column) \n",
        "                self.df[new_column] = np.nan\n",
        "                # update new column by diff\n",
        "                for j in range(differences, len(self.df[new_column])):\n",
        "                      self.df[new_column][j] = self.df[i][j] - self.df[i][j - differences]\n",
        "    \n",
        "              return (self.df[new_column_list])\n",
        "            else:\n",
        "              # raise error  for wrong differences value\n",
        "              raise TypeError(\"\"\"differences = {0} is invalid. The argument: lag only accepts positive integer. \n",
        "                                 \\nExample: df.differencing([\"var1],differences=2)\"\"\".format(differences))\n",
        "\n",
        "        else: \n",
        "          # raise error  for wrong tsColnameList\n",
        "          raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample:  df.differencing([\"var1],differences=2)\"\"\".format(tsColnameList))\n",
        "\n",
        " \n",
        "    def movingaverage(self,tsColnameList,window = 3):\n",
        "        \"\"\" \n",
        "        movingaverage Method:\n",
        "        Updating the selected timeseries data by moving average algorithm \n",
        "        Add the new data as new columns to orginal dataframe.\n",
        "  \n",
        "        Parameters: \n",
        "        tsColnameList (list): The list of columns names\n",
        "        window (int) : window value of moving average algorithm (default = 3)\n",
        "      \n",
        "        Returns: \n",
        "        dataframe: The dataframe of new columns \n",
        "        \"\"\"\n",
        "        if isinstance(tsColnameList, list) and (set(tsColnameList).issubset(self.df.columns.to_list())) :\n",
        "            if isinstance(window, (int)):\n",
        "              new_column_list = []\n",
        "              for i in tsColnameList:\n",
        "                  # setup new cols name\n",
        "                  new_column = str(\"moving_\"+i)\n",
        "                  new_column_list.append(new_column) \n",
        "                  \n",
        "                  def moving_average(x, w):\n",
        "                      # function: compute moving_average\n",
        "                      return np.convolve(x, np.ones(w), 'valid') / w\n",
        "                  # format cols and handling edge value \n",
        "                  x = moving_average(self.df[i], window)\n",
        "                  e = len(self.df[i])  - len(x)\n",
        "                  y = np.zeros(e//2) + np.nan\n",
        "                  z = np.zeros(e-e//2) + np.nan\n",
        "                  # create new column\n",
        "                  self.df[new_column] = np.concatenate((y,x,z), axis=None)\n",
        "              return (self.df[new_column_list])\n",
        "            else:\n",
        "                # raise error  for wrong window value \n",
        "              raise TypeError(\"\"\"window = {0} is invalid. The argument: \n",
        "              lag only accepts positive integer. \n",
        "                                 \\nExample: df.movingaverage([\"var1],window = 3)\"\"\".format(window))\n",
        "        else:\n",
        "            # raise error  for wrong tsColnameList\n",
        "            raise TypeError(\"\"\"tsColnameList = {0} is invalid. The argument: tsColnameList only accepts a list of columns name.\n",
        "                             \\nExample: df.movingaverage([\"var1],window = 3)\"\"\".format(tsColnameList))\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pGs3c41dqRy"
      },
      "source": [
        "# Subclass: **TextDataSet**\n",
        "Public Member Functions\n",
        "```\n",
        "def \t__init__ (self, filename)\n",
        "def \tclean (self, colname, lower=True, remove_diacritics=True, remove_punct=True, remove_stop=True, stem_tokens=False, lemmatize_tokens=False)\n",
        "def \ttoken_list (nested_list)\n",
        "def \texplore (token_list, wordcloud=True, dispersion=True)\n",
        "def \twordfrequency (token_list, n, ascending=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5OFRD5Jdqxp"
      },
      "source": [
        "# Subclass: TextDataSet  \n",
        "class TextDataSet(DataSet):\n",
        "    \n",
        "    def __init__(self, filename):\n",
        "        \"\"\"constructor for subclass, inherited from Dataset\"\"\"\n",
        "        super().__init__(filename)\n",
        "    \n",
        "        DataSet._readFromCSV(self)\n",
        "  \n",
        "    class Clean:\n",
        "        \"\"\"\n",
        "        Clean Class: \n",
        "        The clean class could clean the text \n",
        "        \n",
        "        Parameters:\n",
        "        lower : change text to lower case\n",
        "        remove_diacritics: remove diacritics\n",
        "        remove_punct: remove punctuation\n",
        "        remove_stop: remove stopwords\n",
        "        stem_tokens: stemming\n",
        "        lemmatize_tokens: lemmatization\n",
        "        \n",
        "        \"\"\"\n",
        "       \n",
        "        def __init__(self, lower=True, remove_diacritics=True, remove_punct=True, remove_stop=True, stem_tokens=False, lemmatize_tokens=False):\n",
        "            \n",
        "            self.lower = lower\n",
        "            self.remove_diacritics = remove_diacritics\n",
        "            self.stopwords  = set(nltk.corpus.stopwords.words('english'))\n",
        "            self.remove_stop = remove_stop\n",
        "            self.punct = set(string.punctuation)\n",
        "            self.remove_punct = remove_punct \n",
        "            self.stemmer = PorterStemmer() \n",
        "            self.stem_tokens = stem_tokens\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "            self.lemmatize_tokens = lemmatize_tokens    \n",
        "        \n",
        "        def normalize_string(self, token):\n",
        "            \n",
        "            \"\"\"normalize_string could normalize the string, change n't to not.\"\"\"\n",
        "            \n",
        "            # Make the text to lower case if low is true\n",
        "            if self.lower:\n",
        "    \n",
        "                token = token.lower() if self.lower else token\n",
        "            \n",
        "            # Replace non-spacing charactors with normalized tokens using NFD method\n",
        "            if self.remove_diacritics:\n",
        "                token = regex.sub(\"\\p{Mn}\",'',unicodedata.normalize('NFD',token)) \n",
        "    \n",
        "            if token == \"n't\" and self.stopwords:\n",
        "                token = \"not\"\n",
        "          \n",
        "            return token\n",
        "        \n",
        "        def is_punct(self,text):\n",
        "            \n",
        "            \"\"\"is_punct could evaluate whether the text contains punctuation.\"\"\"\n",
        "            # Return true if there are punctuation or modifier\n",
        "            if text in string.punctuation:\n",
        "                return True\n",
        "            if regex.match(r\"[\\p{P}\\p{Mn}\\p{Sk}]+\", text):\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "        def tokenize(self, text):\n",
        "            \"\"\"tokenize could tokenize the text\"\"\"\n",
        "            tokens = []\n",
        "            # Tokenize text\n",
        "            for token in word_tokenize(text):\n",
        "                stem= \"\"\n",
        "                # Normalize tokens\n",
        "                token_text = self.normalize_string(token)       \n",
        "                if self.remove_punct and self.is_punct(token_text):\n",
        "                    continue\n",
        "                if self.remove_stop and token_text in self.stopwords:\n",
        "                    continue\n",
        "                # Stemming\n",
        "                if self.stem_tokens :\n",
        "                    stem = self.stemmer.stem(token_text)\n",
        "                # Lemmatizing \n",
        "                if self.lemmatize_tokens:\n",
        "                    lemma = self.lemmatizer.lemmatize(token_text)\n",
        "                \n",
        "                # Append the tokens back to list\n",
        "                if self.stem_tokens:\n",
        "                     tokens.append(stem)\n",
        "                elif self.lemmatize_tokens:\n",
        "                    tokens.append(lemma)\n",
        "                else:\n",
        "                    tokens.append(token_text)  \n",
        "                    \n",
        "            return tokens\n",
        "    \n",
        "    \n",
        "    def clean(self, colname, lower=True, remove_diacritics=True, remove_punct=True, remove_stop=True, stem_tokens=False, lemmatize_tokens=False):\n",
        "        \n",
        "        \"\"\"\n",
        "        clean Method:\n",
        "        The clean method could clean a column of text and return a nested token list\n",
        "                    \n",
        "        Parameters:\n",
        "        colname: the column you want to clean\n",
        "        lower : change text to lower case\n",
        "        remove_diacritics: remove diacritics\n",
        "        remove_punct: remove punctuation\n",
        "        remove_stop: remove stopwords\n",
        "        stem_tokens: stemming\n",
        "        lemmatize_tokens: lemmatization\n",
        "        \n",
        "        Returns:\n",
        "        A nested list which can be covert to token list or dataframe\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        # Set the clean method\n",
        "        clean_method=TextDataSet.Clean(lower=lower, remove_diacritics=remove_diacritics, remove_punct=remove_punct, remove_stop=remove_stop, stem_tokens=stem_tokens, lemmatize_tokens=lemmatize_tokens)\n",
        "    \n",
        "        # Clean the column of text and append the tokens back to list\n",
        "        token_data = []\n",
        "        for i in self.df[colname][:]:\n",
        "            tokens = clean_method.tokenize(i)\n",
        "            token_data.append(tokens)\n",
        "        \n",
        "        return token_data\n",
        "    \n",
        "    def token_list(nested_list):\n",
        "        \n",
        "        \"\"\"The token_list could change the nested list to a flat list\"\"\"\n",
        "        \n",
        "        # Check whether the input is a nested list\n",
        "        if any(isinstance(i, list) for i in nested_list) == False:\n",
        "            raise TypeError(\"The nested_list is not nested.\")\n",
        "        \n",
        "        # Make the nested list to flat list\n",
        "        else:\n",
        "            flat_list = []\n",
        "            for sublist in nested_list:\n",
        "                for item in sublist:\n",
        "                    flat_list.append(item)\n",
        "            return flat_list\n",
        "    \n",
        "\n",
        "    def explore(token_list, wordcloud=True, dispersion=True):\n",
        "        \n",
        "        \"\"\"T\n",
        "        explore Method:\n",
        "        he explore could produce worldcloud and dispersion plot\n",
        "        \n",
        "        Parameters:\n",
        "        token_list: a list of tokens\n",
        "        wordcloud: produce wordcloud\n",
        "        dispersion: produce dispersion plot\n",
        "        \n",
        "        Returns:\n",
        "        wordcloud plot and dispersion plot\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        # Check wehter the input is a list\n",
        "        if isinstance(token_list, list) == False:\n",
        "            raise ValueError(\"The format of token_list is incorrect.\")\n",
        "        \n",
        "        # Raise exception if both arributes are False\n",
        "        elif wordcloud==False and dispersion==False:\n",
        "            raise Exception(\"No plot will be made\")\n",
        "        \n",
        "        # Make world cloud\n",
        "        if wordcloud:\n",
        "            my_string = (\" \").join(token_list)\n",
        "            my_wordcloud= WordCloud().generate(my_string)\n",
        "    \n",
        "            # Display the generated image:\n",
        "            plt.imshow(my_wordcloud, interpolation='bilinear')\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "        \n",
        "        # Make dispersion plot \n",
        "        elif dispersion:\n",
        "            search_words=[\"like\", \"love\", \"adore\", \"dislike\", \"hate\", \"abhor\", \"detest\", \"sickening\"]\n",
        "            dispersion_plot(token_list, search_words, ignore_case=True, title=\"Dispersion of emotional words\")\n",
        "       \n",
        "        \n",
        "\n",
        "    def wordfrequency(token_list,n,ascending= True):\n",
        "        \n",
        "        \"\"\"\n",
        "        wordfrequency Method:\n",
        "        The wordfrequency could produce the wordfrequency dataframe\n",
        "        \n",
        "        Parameters:\n",
        "        token_list: a list of tokens\n",
        "        n: number of rows you want to check \n",
        "        ascending: the order of the wordfrequency\n",
        "        \n",
        "        Return:\n",
        "        A wordfrequency dataframe \n",
        "    \n",
        "        \"\"\"\n",
        "        \n",
        "        # Check wehter the input is a list\n",
        "        if isinstance(token_list, list) == False:\n",
        "            raise ValueError(\"The format of token_list is incorrect.\")\n",
        "        \n",
        "        # Check whether n is an integer\n",
        "        elif isinstance(n, int) == False:\n",
        "            raise ValueError(\"n should be an integer.\")\n",
        "    \n",
        "        else:\n",
        "            # count the words\n",
        "            counts = Counter(token_list)\n",
        "            \n",
        "            # Make the counts to dataframe\n",
        "            df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
        "            df = df.rename(columns={'index':'words', 0:'frequency'})\n",
        "            if ascending:\n",
        "                df = df.sort_values('frequency',ascending=True)\n",
        "            else:\n",
        "                df = df.sort_values('frequency',ascending=False)\n",
        "            print(df.head(n))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px65gsXkd8J7"
      },
      "source": [
        "# subclass **QuantDataSet**\n",
        "\n",
        "Public Member Functions\n",
        "```\n",
        "def \t__init__ (self, filename)\n",
        "def \tclean (self)\n",
        "def \texplore (self, plot_type, column1, column2=None)\n",
        "def \tmean (self, column_name)\n",
        "def \tmedian (self, column_name_median)\n",
        "def \tmode (self, column_name_mode)\n",
        "def \torder (self, column_name_order, decreasing)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbOkj2hhd8fR"
      },
      "source": [
        "# subclass QuantDataSet of our super class\n",
        "class QuantDataSet(DataSet):\n",
        "    \"\"\"This is a class used for cleaning, plotting and doing some calculating work for a quantitative dataset\"\"\"\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        \"\"\"constructor for subclass, inherited from Dataset\"\"\"\n",
        "        super().__init__(filename)\n",
        "        DataSet._readFromCSV(self)\n",
        "\n",
        "    def clean(self):\n",
        "        \"\"\"\n",
        "        clean Method:\n",
        "        Fill in missing values with the mean of its column\n",
        "\n",
        "        Parameters:\n",
        "        inherit the variable from the above\n",
        "\n",
        "        Returns:\n",
        "        Clean dataset\n",
        "        \"\"\"\n",
        "\n",
        "        Quant_dataset = self.df\n",
        "        # the number of columns\n",
        "        count_row = Quant_dataset.shape[0]\n",
        "        count_col = Quant_dataset.shape[1]\n",
        "        colList = []\n",
        "        rowList = []\n",
        "        for indexs in range(count_row):\n",
        "            for i in range(count_col):\n",
        "                a = Quant_dataset.loc[indexs].values[i]\n",
        "                # a=Quant_dataset.iloc(indexs,i)\n",
        "                if pd.isna(a):\n",
        "                    # catch the row number and column number\n",
        "                    rowList.append(indexs)\n",
        "                    colList.append(i)\n",
        "\n",
        "        # fill in missing values with the mean of its column\n",
        "        count_NA = len(rowList)\n",
        "        for i in range(count_NA):\n",
        "            Quant_dataset.iloc[rowList[i], colList[i]] = Quant_dataset[colList[i]].mean()\n",
        "        print(\"Cleaning finished, we have filled all the missing values with the mean of its column\")\n",
        "\n",
        "    # the explore method\n",
        "    def explore(self, plot_type, column1, column2=None):\n",
        "        \"\"\"G\n",
        "        explore Method:\n",
        "        ive a histogram or a scatter plot of a certain column or 2 columns\n",
        "\n",
        "        Parameters:\n",
        "        plot_type: the type of the plot\n",
        "        column1 (string): the column will be used in the histogram or the scatter plot\n",
        "        column2=None (string): the another column will be used in the scatter plot\n",
        "\n",
        "        Returns:\n",
        "        the histogram or the scatter plot\n",
        "        \"\"\"\n",
        "        self.column1 = column1\n",
        "        self.column2 = column2\n",
        "        self.plot_type = plot_type\n",
        "        Quant_dataset = self.df\n",
        "\n",
        "        if plot_type == \"hist\":\n",
        "            # Plot the hist of a certain column\n",
        "            if self.column1 in Quant_dataset.columns.values:\n",
        "                plt.figure(figsize=(8, 6), dpi=80)\n",
        "                plt.hist(Quant_dataset[self.column1])\n",
        "                plt.title(self.column1)\n",
        "                plt.xlabel(self.column1)\n",
        "                plt.ylabel('Count')\n",
        "                plt.show()\n",
        "            else:\n",
        "                # raise error when input a wrong column name\n",
        "                raise KeyError('The column name is incorrect!')\n",
        "        elif plot_type == \"scatter\":\n",
        "            # Plot the scatter plot to show the relationship between 2 certain columns\n",
        "            if self.column1 and self.column2 in Quant_dataset.columns.values:\n",
        "                plt.figure(figsize=(8, 6), dpi=80)\n",
        "                plt.scatter(Quant_dataset[self.column1], Quant_dataset[self.column2])\n",
        "                plt.title(\"The scatter plot\")\n",
        "                plt.xlabel(self.column1)\n",
        "                plt.ylabel(self.column2)\n",
        "                plt.show()\n",
        "            else:\n",
        "                # raise error when input wrong column names\n",
        "                raise KeyError('The column name is incorrect!')\n",
        "        else:\n",
        "            # raise error when input wrong plot types\n",
        "            raise ValueError('The plot type is incorrect! Please type in scatter or hist!')\n",
        "\n",
        "    def mean(self, column_name):\n",
        "        \"\"\"\n",
        "        mean Method:\n",
        "        Return the mean of a certain column\n",
        "\n",
        "        Parameter:\n",
        "        column_name (string): the column to calculate the mean\n",
        "\n",
        "        Returns:\n",
        "        float: the mean of the certain column\n",
        "        \n",
        "        \"\"\"\n",
        "        Quant_dataset = self.df\n",
        "        self.column_name = column_name\n",
        "        # the mean of each column\n",
        "        if self.column_name in Quant_dataset.columns.values:\n",
        "            try:\n",
        "                a = Quant_dataset[self.column_name]\n",
        "                b = a.mean()\n",
        "                print(\"the mean of the column \" + self.column_name + \" is\", b)\n",
        "            except (ValueError, TypeError):\n",
        "                print(\"The column \", self.column_name, \" is not numeric\")\n",
        "        else:\n",
        "            # raise error when input wrong column names\n",
        "            raise ValueError('The column name is incorrect!')\n",
        "\n",
        "    def median(self, column_name_median):\n",
        "        \"\"\"\n",
        "        median Method:\n",
        "        Return the median of a certain column\n",
        "\n",
        "        Parameter:\n",
        "        column_name_median (string): the column to calculate the median\n",
        "\n",
        "        Returns:\n",
        "        float: the median of the certain column\n",
        "        \n",
        "        \"\"\"\n",
        "        Quant_dataset = self.df\n",
        "        self.column_name_median = column_name_median\n",
        "        # the median of each column\n",
        "        if self.column_name_median in Quant_dataset.columns.values:\n",
        "            try:\n",
        "                a = Quant_dataset[self.column_name_median]\n",
        "                b = a.median()\n",
        "                print(\"the median of the column \" + self.column_name_median + \" is\", b)\n",
        "            except (ValueError, TypeError):\n",
        "                print(\"The column \", self.column_name_median, \" is not numeric\")\n",
        "        else:\n",
        "            # raise error when input wrong column names\n",
        "            raise ValueError('The column name is incorrect!')\n",
        "\n",
        "    def mode(self, column_name_mode):\n",
        "        \"\"\"\n",
        "        mode Method:\n",
        "        Return the mode of a certain column\n",
        "\n",
        "        Parameter:\n",
        "        column_name_mode (string): the column to calculate the mode\n",
        "\n",
        "        Returns:\n",
        "        float: the mode of the certain column\n",
        "        \n",
        "        \"\"\"\n",
        "        Quant_dataset = self.df\n",
        "        self.column_name_mode = column_name_mode\n",
        "        # the mode of the column\n",
        "        if self.column_name_mode in Quant_dataset.columns.values:\n",
        "            try:\n",
        "                a = Quant_dataset[self.column_name_mode]\n",
        "                b = a.values.tolist()\n",
        "                dict = {}\n",
        "                for key in b:\n",
        "                    dict[key] = dict.get(key, 0) + 1\n",
        "                d_order = sorted(dict.items(), key=lambda x: x[1], reverse=True)\n",
        "                mode = d_order[0][0]\n",
        "                print(\"the mode of the column \" + self.column_name_mode + \" is\", mode)\n",
        "            except (ValueError, TypeError):\n",
        "                print(\"The column \", self.column_name_mode, \" is not numeric\")\n",
        "        else:\n",
        "            # raise error when input wrong column names\n",
        "            raise ValueError('The column name is incorrect!')\n",
        "\n",
        "    def order(self, column_name_order, decreasing):\n",
        "        \"\"\"\n",
        "        order Method:\n",
        "        Present dataset by specific order\n",
        "\n",
        "        Parameter:\n",
        "        column_name_order (string): the column used to sort the dataset\n",
        "        decreasing=False/True :the order type\n",
        "\n",
        "        Returns:\n",
        "        dataframe: the sorted dataset\n",
        "        \n",
        "        \"\"\"   \n",
        "        self.column_name_order = column_name_order\n",
        "        self.decreasing = decreasing\n",
        "        Quant_dataset = self.df\n",
        "\n",
        "        if self.column_name_order in Quant_dataset.columns.values:\n",
        "            if self.decreasing == True:\n",
        "                decrease_df = Quant_dataset.sort_values(by=self.column_name_order, ascending=False)\n",
        "                print(decrease_df)\n",
        "            elif self.decreasing == False:\n",
        "                increase_df = Quant_dataset.sort_values(by=self.column_name_order, ascending=True)\n",
        "                print(increase_df)\n",
        "            else:\n",
        "                raise ValueError('The parameter decreasing is incorrect! Please input True or False')\n",
        "        else:\n",
        "            # raise error when input wrong column names\n",
        "            raise ValueError('The column name is incorrect!')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgMuerFed_dR"
      },
      "source": [
        "# subclass **QualDataSet**\n",
        "\n",
        "Public Member Functions\n",
        "```\n",
        "def \t__init__ (self, filename)\n",
        "def \tclean (self)\n",
        "def \texplore (self, plot_type_qual, column_qual)\n",
        "def \ttable (self, column_table)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxnPfG8WeAHU"
      },
      "source": [
        "# subclass QualDataSet of our super class\n",
        "class QualDataSet(DataSet):\n",
        "    \"\"\"This is a class used for clean, plot and see the category frequency of a qualitative dataset\"\"\"\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        \"\"\"constructor for subclass, inherited from Dataset\"\"\"\n",
        "        super().__init__(filename)\n",
        "        DataSet._readFromCSV(self)\n",
        "\n",
        "    def clean(self):\n",
        "        \"\"\"\n",
        "        clean Method:  \n",
        "        Fill in missing values with the mode of its column\n",
        "\n",
        "        Parameter:\n",
        "        inherited from the Dataset class\n",
        "\n",
        "        Return:\n",
        "        the cleaned dataset\n",
        "        \"\"\"\n",
        "        Qual_dataset = self.df\n",
        "        # the number of columns and rows\n",
        "        count_row = Qual_dataset.shape[0]\n",
        "        count_col = Qual_dataset.shape[1]\n",
        "        colList = []\n",
        "        rowList = []\n",
        "        for indexs in range(count_row):\n",
        "            for i in range(count_col):\n",
        "                a = Qual_dataset.loc[indexs].values[i]\n",
        "                if pd.isna(a):\n",
        "                    # catch the row number and column number of NAs\n",
        "                    rowList.append(indexs)\n",
        "                    colList.append(i)\n",
        "        # fill in missing values with the mode of its column\n",
        "        count_NA = len(rowList)\n",
        "        for i in range(count_NA):\n",
        "            a = Qual_dataset[Qual_dataset.columns.values[colList[i]]]\n",
        "            b = a.values.tolist()\n",
        "            dict = {}\n",
        "            for key in b:\n",
        "                dict[key] = dict.get(key, 0) + 1\n",
        "            d_order = sorted(dict.items(), key=lambda x: x[1], reverse=True)\n",
        "            mode = d_order[0][0]\n",
        "            if pd.isna(mode):\n",
        "                mode = d_order[1][0]\n",
        "            Qual_dataset.iloc[rowList[i], colList[i]] = mode\n",
        "        print(\"Cleaning finished, we have filled all the missing values with the mode of its column\")\n",
        "\n",
        "    def explore(self, plot_type_qual, column_qual):\n",
        "        \"\"\"\n",
        "        explore Method:\n",
        "        Give a histogram or a pie chart of a certain column\n",
        "\n",
        "        Parameters:\n",
        "        plot_type_qual (string): the plot type --pie or hist\n",
        "        column_qual (string): the column used for create the plot\n",
        "\n",
        "        Return:\n",
        "        a pie chart or a histogram\n",
        "        \"\"\"\n",
        "        \n",
        "        Qual_dataset = self.df\n",
        "        self.column_qual = column_qual\n",
        "        self.plot_type_qual = plot_type_qual\n",
        "\n",
        "        if self.plot_type_qual == \"hist\":\n",
        "            # give a histogram of a certain column to show the frequency of each category\n",
        "            if column_qual in Qual_dataset.columns.values:\n",
        "                try:\n",
        "                    plt.figure(figsize=(8, 6), dpi=80)\n",
        "                    plt.hist(Qual_dataset[self.column_qual])\n",
        "                    plt.title(self.column_qual)\n",
        "                    plt.xlabel(self.column_qual)\n",
        "                    plt.ylabel('Frequency')\n",
        "                    plt.show()\n",
        "                except(ValueError, TypeError):\n",
        "                    print(\"The column \", self.plot_type_qual, \"has NA values, please clean it\")\n",
        "            else:\n",
        "                # raise error when input a wrong column name\n",
        "                raise KeyError('The column name is incorrect!')\n",
        "\n",
        "        elif self.plot_type_qual == \"pie\":\n",
        "            # give a pie chart of a certain column to show the proportion of each category\n",
        "            if column_qual in Qual_dataset.columns.values:\n",
        "                a = Qual_dataset[self.column_qual]\n",
        "                b = a.values.tolist()\n",
        "                dict = {}\n",
        "                for key in b:\n",
        "                    dict[key] = dict.get(key, 0) + 1\n",
        "                labels = []\n",
        "                values = []\n",
        "                for i in dict.keys():\n",
        "                    labels.append(i)\n",
        "                for j in dict.values():\n",
        "                    values.append(j)\n",
        "                fig = plt.figure()\n",
        "                plt.pie(values, labels=labels, autopct='%1.2f%%')\n",
        "                plt.title(\"Pie Chart\")\n",
        "                plt.show()\n",
        "            else:\n",
        "                # raise error when input a wrong column name\n",
        "                raise KeyError('The column name is incorrect!')\n",
        "        else:\n",
        "            # raise error when input a wrong plot type\n",
        "            raise ValueError('The plot type is incorrect! Please type in pie or hist')\n",
        "\n",
        "    def table(self, column_table):\n",
        "        \"\"\"\n",
        "        table Method:\n",
        "            \n",
        "        Show the frequency of each category for a certain column\n",
        "\n",
        "        Parameter:\n",
        "        column_table(string): the column to be tabled\n",
        "\n",
        "        Return:\n",
        "        dictionary: the frequency of each category in the certain column \n",
        "        \n",
        "        \"\"\"\n",
        "        Qual_dataset = self.df\n",
        "        self.column_table = column_table\n",
        "\n",
        "        if column_table in Qual_dataset.columns.values:\n",
        "            a = Qual_dataset[self.column_table]\n",
        "            b = a.values.tolist()\n",
        "            dict = {}\n",
        "            for key in b:\n",
        "                dict[key] = dict.get(key, 0) + 1\n",
        "            return (dict)\n",
        "        else:\n",
        "            # raise error when input a wrong column name\n",
        "            raise KeyError('The column name is incorrect!')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}